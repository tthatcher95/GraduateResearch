{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import math\n",
    "import urllib.request\n",
    "# from bs4 import BeautifulSoup\n",
    "from operator import itemgetter\n",
    "import networkx as nx\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def native_vote_csv_df():\n",
    "    filepath = \"/Users/tdt62/Desktop/GraduateResearch/test_data/2018_10_17_09_vote*\"\n",
    "    list_ = []\n",
    "\n",
    "#     filepath = \"/projects/canis/nativevote18/twitter/data/2018_10_17_09_vote_stream_1_clean.csv\"\n",
    "#     filepath = \"/projects/canis/nativevote18/twitter/data/2018_10_*vote*\"\n",
    "\n",
    "    # Takes all of the csv file and makes one big dataframe\n",
    "    for name in glob.glob(filepath):\n",
    "        if(os.stat(name).st_size == 0) == True:\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_csv(name,index_col=None, sep='\\t')\n",
    "            list_.append(df)\n",
    "\n",
    "#     filepath = \"/projects/canis/nativevote18/twitter/data/2018_11*stream_1*\"\n",
    "# #     filepath = \"/Users/tdt62/Desktop/GraduateResearch/test_data/2018_11_*vote*\"\n",
    "\n",
    "#     # Takes all of the csv file and makes one big dataframe\n",
    "#     for name in glob.glob(filepath):\n",
    "#         if(os.stat(name).st_size == 0) == True:\n",
    "#             continue\n",
    "#         else:\n",
    "#             df = pd.read_csv(name,index_col=None, header=0)\n",
    "#             list_.append(df)\n",
    "\n",
    "#     filepath = \"/projects/canis/nativevote18/twitter/data/2018_12*stream_1*\"\n",
    "# #     filepath = \"/Users/tdt62/Desktop/test_data/2018_12_01*vote*\"\n",
    "\n",
    "#         # Takes all of the csv file and makes one big dataframe\n",
    "#         for name in glob.glob(filepath):\n",
    "#             if(os.stat(name).st_size == 0) == True:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 df = pd.read_csv(name,index_col=None, header=0)\n",
    "#                 list_.append(df)\n",
    "\n",
    "#         filepath = \"/projects/canis/nativevote18/twitter/data/2019_01*stream_1*\"\n",
    "\n",
    "#     # Takes all of the csv file and makes one big dataframe\n",
    "#     for name in glob.glob(filepath):\n",
    "#         if(os.stat(name).st_size == 0) == True:\n",
    "#             continue\n",
    "#         else:\n",
    "#             df = pd.read_csv(name,index_col=None, header=0)\n",
    "#             list_.append(df)\n",
    "\n",
    "    # Makes the big df in memory\n",
    "    frame = pd.concat(list_, axis = 0, ignore_index = True)\n",
    "    frame.fillna(\"NA\", inplace=True)\n",
    "    return frame\n",
    "\n",
    "def total_tweets(df):\n",
    "\n",
    "    # Gets the total number of tweets\n",
    "    total_tweets_num = df.shape[0]  # gives number of row count\n",
    "    return total_tweets_num\n",
    "\n",
    "def unique_tweets(df):\n",
    "\n",
    "    # Gets the unique tweets i.e. no retweeted status\n",
    "    df['rt_isdigit'] = list(map(lambda x: str(x).isdigit(), df['Reteeted_Status']))\n",
    "    unique_df = df.loc[df['rt_isdigit'] == False]\n",
    "    return unique_df\n",
    "\n",
    "def unique_users(df):\n",
    "    unique_users = len(df.User_ID.unique())\n",
    "    return unique_users\n",
    "\n",
    "def original_content_user(df):\n",
    "\n",
    "    # Gets the unique tweets i.e. no retweeted status\n",
    "    df['rt_isdigit'] = list(map(lambda x: str(x).isdigit(), df['Reteeted_Status']))\n",
    "    unique_df = df.loc[df['rt_isdigit'] == False]\n",
    "    unique_users = len(unique_df.User_ID.unique())\n",
    "    return unique_users\n",
    "\n",
    "def hashtags(df, top_val):\n",
    "\n",
    "    top_list = []\n",
    "    hashtag_dict = {}\n",
    "\n",
    "    def iterate_hashtags(x):\n",
    "        hashtag_list = list(x.split(\"'text':\"))\n",
    "        for element in hashtag_list:\n",
    "            stripped_element = element.split(',')[0].strip(\"' '{}[]\")\n",
    "            if stripped_element in hashtag_dict and stripped_element != '[]' and stripped_element != 'NA' and stripped_element != '':\n",
    "                hashtag_dict[stripped_element] += 1\n",
    "            else:\n",
    "                hashtag_dict[stripped_element] = 1\n",
    "\n",
    "    # Create the hashtag dict\n",
    "    list(map(lambda x: iterate_hashtags(x), df['Hashtags']))\n",
    "\n",
    "    # Gets the sorted news_list in descending order\n",
    "    sorted_news_list = (list(sorted(hashtag_dict.items(), key=itemgetter(1), reverse=True)))\n",
    "\n",
    "    # Gets the top 20 results of the sorted list\n",
    "    sorted_news_list = sorted_news_list[0:top_val]\n",
    "\n",
    "    # Stores all the names in a list, so we can read correctky\n",
    "    for item in sorted_news_list:\n",
    "        top_list.append(item[0])\n",
    "\n",
    "    return top_list, sorted_news_list\n",
    "\n",
    "def make_domain_csv(top_news_dict):\n",
    "    with open('news_domains.csv', 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in top_news_dict.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "def top_user_mentions(df, top_val):\n",
    "\n",
    "    top_users_list = []\n",
    "    hashtag_dict = {}\n",
    "\n",
    "    def iterate_user_mentions(x):\n",
    "\n",
    "        hashtag_list = list(x.split(\"'screen_name':\"))\n",
    "        for element in hashtag_list:\n",
    "            stripped_element = element.split(',')[0].strip(\"' '{}[]\")\n",
    "            if stripped_element in hashtag_dict and stripped_element != '[]' and stripped_element != 'NA' and stripped_element != '':\n",
    "                hashtag_dict[stripped_element] += 1\n",
    "            else:\n",
    "                hashtag_dict[stripped_element] = 1\n",
    "\n",
    "    # Create the hashtag dict\n",
    "    list(map(lambda x: iterate_user_mentions(x), df['User_Mentions']))\n",
    "\n",
    "    # Gets the sorted news_list in descending order\n",
    "    sorted_news_list = (list(sorted(hashtag_dict.items(), key=itemgetter(1), reverse=True)))\n",
    "\n",
    "    # Gets the top 20 results of the sorted list\n",
    "    sorted_news_list = sorted_news_list[0:top_val]\n",
    "\n",
    "    # Stores all the names in a list, so we can read correctky\n",
    "    for item in sorted_news_list:\n",
    "        top_users_list.append(item[0])\n",
    "\n",
    "    return top_users_list, sorted_news_list\n",
    "\n",
    "def get_hashtag_users_df(df):\n",
    "        hashtag_users_df = df.loc[(df['User_Mentions'] != '[]') & (df['Hashtags'] != '[]')]\n",
    "        return hashtag_users_df\n",
    "\n",
    "def build_mentions_dict(df):\n",
    "\n",
    "    def make_csv(user_hashtag_dict):\n",
    "        with open('user_hashtag.csv', 'w') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            for key, value in user_hashtag_dict.items():\n",
    "                writer.writerow([key, value])\n",
    "\n",
    "    def make_lists(df):\n",
    "        user_list = list(df['User_Mentions'].split(\"'screen_name':\"))\n",
    "        hashtag_list = list(df['Hashtags'].split(\"'text':\"))\n",
    "\n",
    "\n",
    "\n",
    "    user_list = list(df['User_Mentions'].split(\"'screen_name':\"))\n",
    "    hashtag_list = list(df['Hashtags'].split(\"'text':\"))\n",
    "\n",
    "    for user in user_list:\n",
    "        stripped_user = user.split(',')[0].strip(\"' '{}[]\")\n",
    "        if stripped_user != '[]' and stripped_user != 'NA' and stripped_user != '':\n",
    "            for hashtag in hashtag_list:\n",
    "                stripped_hashtag = hashtag.split(',')[0].strip(\"' '{}[]\")\n",
    "                if stripped_hashtag != '[]' and stripped_hashtag != 'NA' and stripped_hashtag != '':\n",
    "                    dict_tuple = (stripped_user, stripped_hashtag)\n",
    "                    if(dict_tuple in user_hashtag_dict):\n",
    "                        user_hashtag_dict[dict_tuple] += 1\n",
    "                    else:\n",
    "                        user_hashtag_dict[dict_tuple] = 1\n",
    "    make_csv(user_hashtag_dict)\n",
    "    return user_hashtag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_Mentions'] \n",
      "\n",
      "\n",
      "[\"{'NicolleDWallace': 860555190}\"] \n",
      "\n",
      "\n",
      "[\"{'jn4ush': 899371613396893696, 'SamuelWestOK': 1446455844}\"] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "[\"{'MickCornett': 18812454, '1AmericanMama': 1031250716243968000}\"] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "[\"{'DinoRossiWA': 146241212}\"] \n",
      "\n",
      "\n",
      "[\"{'KristiNoem': 114388293}\"] \n",
      "\n",
      "\n",
      "[\"{'SenatorHeitkamp': 1061029050, 'TrahantReports': 28358250, 'StandingRockST': 772941628134699008, 'levinecarrie': 366602165, 'Deb4CongressNM': 286476728, 'SimonMoyaSmith': 89788739, '1a': 793442243734544384}\"] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "[\"{'PauletteEJordan': 2942421722}\"] \n",
      "\n",
      "\n",
      "[\"{'PauletteEJordan': 2942421722}\"] \n",
      "\n",
      "\n",
      "[\"{'PauletteEJordan': 2942421722}\"] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "[\"{'sharicedavids': 950952511556538368}\"] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "[\"{'KamalaHarris': 30354991, 'SenWarren': 970207298, 'alanslj': 346108609, 'RepThompson': 303861808, 'LisaServon': 369273877}\"] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n",
      "['{}'] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "24     {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "28     {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "63     {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "65     {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "67     {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "88     {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "125    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "156    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "161    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "163    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "165    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "177    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "263    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "279    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "310    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "362    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "377    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "386    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "389    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "392    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "397    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "408    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "413    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "414    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "419    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "425    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "445    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "479    {('User_Mentions', 'Hashtags'): 1, ('NicolleDW...\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_df = native_vote_csv_df()\n",
    "\n",
    "unique_df = unique_tweets(native_df)\n",
    "\n",
    "hashtag_user_df = get_hashtag_users_df(unique_df)\n",
    "\n",
    "user_hashtag_dict = {}\n",
    "\n",
    "def build_mentions_dict(df):\n",
    "    \n",
    "    def make_csv(user_hashtag_dict):\n",
    "        with open('user_hashtag.csv', 'w') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            for key, value in user_hashtag_dict.items():\n",
    "                writer.writerow([key, value])\n",
    "            \n",
    "    \n",
    "    user_list = list(df['User_Mentions'].split(\"'screen_name':\"))\n",
    "    hashtag_list = list(df['Hashtags'].split(\"'text':\"))\n",
    "    print(user_list, '\\n\\n')\n",
    "                        \n",
    "    for user in user_list:\n",
    "        stripped_user = user.split(',')[0].strip(\"' '{}[]\")\n",
    "        if stripped_user != '[]' and stripped_user != 'NA' and stripped_user != '':\n",
    "            for hashtag in hashtag_list:\n",
    "                stripped_hashtag = hashtag.split(',')[0].strip(\"' '{}[]\")\n",
    "                if stripped_hashtag != '[]' and stripped_hashtag != 'NA' and stripped_hashtag != '':\n",
    "                    dict_tuple = (stripped_user, stripped_hashtag)\n",
    "#                     print(dict_tuple)\n",
    "                    if(dict_tuple in user_hashtag_dict):\n",
    "                        user_hashtag_dict[dict_tuple] += 1\n",
    "                    else:\n",
    "                        user_hashtag_dict[dict_tuple] = 1\n",
    "    make_csv(user_hashtag_dict)\n",
    "    return user_hashtag_dict\n",
    "                        \n",
    "\n",
    "\n",
    "            \n",
    "hashtag_user_df.apply(build_mentions_dict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"NicolleDWallace\\': 860555190\"', '\"jn4ush\\': 899371613396893696\"', '\"MickCornett\\': 18812454\"', '\"DinoRossiWA\\': 146241212\"', '\"KristiNoem\\': 114388293\"', '\"SenatorHeitkamp\\': 1061029050\"', '\"PauletteEJordan\\': 2942421722\"', '\"sharicedavids\\': 950952511556538368\"', '\"KamalaHarris\\': 30354991\"']\n",
      "0.11666666666666665 0.7650079429261462\n",
      "--- Jaccard ---\n",
      "VoteMeTooPAC VoteMeTooPAC 1.0\n",
      "powertweet powertweet 1.0\n",
      "GOP GOP 1.0\n",
      "Ballots Ballots 1.0\n",
      "MAGA MAGA 1.0\n",
      "NoDAPL NoDAPL 1.0\n",
      "imwithpaulette imwithpaulette 1.0\n",
      "ElectWomen ElectWomen 1.0\n",
      "studentloans studentloans 1.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"user_hashtag.csv\", names=['User_Hashtag', 'Count'])\n",
    "df\n",
    "\n",
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "bi1_list = []\n",
    "bi2_list = []\n",
    "\n",
    "for val in df['User_Hashtag'][1:]:\n",
    "    x = val.split(',')\n",
    "#     print(x[0].strip())\n",
    "    bi1_list.append(x[0].strip(\" ''()\"))\n",
    "    bi2_list.append(x[1].strip(\" ''()\"))\n",
    "\n",
    "print(bi1_list)\n",
    "B.add_nodes_from(set(bi1_list), bipartite=1)\n",
    "B.add_nodes_from(set(bi2_list), bipartite=0)\n",
    "B.add_edges_from(list(zip(bi1_list, bi2_list)))\n",
    "\n",
    "pos = {}\n",
    "\n",
    "# Update position for node from each group\n",
    "pos.update((node, (1, index)) for index, node in enumerate(bi2_list))\n",
    "pos.update((node, (2, index)) for index, node in enumerate(bi1_list))\n",
    "preds = list(nx.jaccard_coefficient(B, list(zip(bi2_list, bi2_list))))\n",
    "jaccard_dict = {}\n",
    "from scipy import stats\n",
    "rho, pval = stats.spearmanr(bi2_list, bi1_list)\n",
    "print(rho, pval)\n",
    "print(\"--- Jaccard ---\")\n",
    "\n",
    "for n1, n2, j in preds:\n",
    "    print(n1, n2, j)\n",
    "    jaccard_dict[(n1, n2)] = j\n",
    "\n",
    "def make_csv(jaccard_dict):\n",
    "    with open('jaccard_projection.csv', 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Usertag, Hashtag', 'JaccardSim'])\n",
    "        for key, value in user_hashtag_dict.items():\n",
    "            writer.writerow([key, value])\n",
    "make_csv(jaccard_dict)\n",
    "# print(preds)\n",
    "# print(\"--- Jaccard ---\")\n",
    "# for n1, n2, j in preds:\n",
    "#     print(\"{}, {}: {}\".format(n1, n2, j))\n",
    "# print(\"--- Jaccard ---\\n\\n\")\n",
    "# nx.draw(B, pos=pos, with_labels = True)\n",
    "# nx.bipartite.sets(B, top_nodes=bi1_list)\n",
    "# G = nx.bipartite.weighted_projected_graph(B, bi1_list)\n",
    "# nx.draw(G, with_labels = True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'community'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af7df1526897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcommunity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#better with karate_graph() as defined in networkx example.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'community'"
     ]
    }
   ],
   "source": [
    "import community\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#better with karate_graph() as defined in networkx example.\n",
    "#erdos renyi don't have true community structure\n",
    "G = nx.erdos_renyi_graph(30, 0.05)\n",
    "\n",
    "#first compute the best partition\n",
    "partition = community.best_partition(G)\n",
    "\n",
    "#drawing\n",
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(G)\n",
    "count = 0.\n",
    "for com in set(partition.values()) :\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(G, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n",
    "\n",
    "\n",
    "nx.draw_networkx_edges(G,pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
